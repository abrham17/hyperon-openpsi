from typing import List, Any, Optional

from langchain_core.runnables import RunnableConfig

from langgraph.checkpoint.memory import InMemorySaver


# from adapter import *
from hyperon import *
from hyperon.ext import register_atoms
from hyperon.atoms import (
    OperationAtom,
    ValueAtom,
    E,
    ExpressionAtom,
)
import os
from dotenv import load_dotenv

from typing import Annotated, TypedDict

from langgraph.graph import add_messages, MessagesState, StateGraph
from langchain_core.messages import (
    AIMessage,
    HumanMessage,
    RemoveMessage,
    SystemMessage,
)
from langgraph.graph import END
from langchain_google_genai import ChatGoogleGenerativeAI

from pydantic import BaseModel

import re


def validateSyntax(rule: str) -> bool:
    rule = rule.strip()

    # Adjusted regex to support underscores and multi-line formatting
    pattern = re.compile(
        r"""
        ^\(\(:\s*\w+\s+                                   # rule ID (e.g., r7)
        \(\(TTV\s+\d+\s+\(STV\s+[0-9.]+\s+[0-9.]+\)\)\s+   # TTV and STV
        \(IMPLICATION_LINK\s+
            \(AND_LINK\s+
                \(\(Goal\s+[\w\-]+                         # Goal name (allowing _)
                \s+[0-9.]+\s+[0-9.]+\)\s+                   # Goal confidence values
                [\w\-]+\)\)\s+                             # Action name (with _ allowed)
            \(Goal\s+[\w\-]+\s+[0-9.]+\s+[0-9.]+\)         # Goal conclusion
        \)\)\)\s+[0-9.]+\)$                                # trailing number (score)
        """,
        re.VERBOSE | re.DOTALL,
    )

    return bool(pattern.match(rule))


def validateExistence(rule: str, ruleSpace: List[str]) -> bool:
    """
    Validates if a rule string exists within the ruleSpace string.
    """
    # This is a simple validation . It  assumes there is no discrepancy in the spacing within the rule strings.

    return rule in ruleSpace


class Schema(BaseModel):
    handle: str
    context: str
    action: str
    goal: str
    weight: float | str = 0
    tv: str | None = None


load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
# Initialize the Gemini model
conversation_model = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",  # Specify the model (e.g., gemini-1.5-flash, gemini-1.5-pro)
    temperature=0,  # Control randomness (0 for deterministic)
    max_tokens=None,  # Maximum tokens in response (optional)
    timeout=None,  # Request timeout (optional)
    max_retries=2,  # Number of retries for failed requests
    google_api_key=api_key,  # Use environment variable
)
summarization_model = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",  # Specify the model (e.g., gemini-1.5-flash, gemini-1.5-pro)
    temperature=0,  # Control randomness (0 for deterministic)
    max_tokens=None,  # Maximum tokens in response (optional)
    timeout=None,  # Request timeout (optional)
    max_retries=2,  # Number of retries for failed requests
    google_api_key=api_key,  # Use environment variable
)


model = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",  # Specify the model (e.g., gemini-1.5-flash, gemini-1.5-pro)
    temperature=0,  # Control randomness (0 for deterministic)
    max_tokens=None,  # Maximum tokens in response (optional)
    timeout=None,  # Request timeout (optional)
    max_retries=2,  # Number of retries for failed requests
    google_api_key=api_key,  # Use environment variable
)


class SchemaList(BaseModel):
    rules: List[Schema]


# correlation_model = model.with_structured_output(SchemaList)
correlation_model = model.with_structured_output(SchemaList)


SYSTEM_PROMPT = """
You are an emotional LLM agent designed to respond to questions with a tone and style influenced by a provided emotion vector. Your inputs will always include:

An emotion vector string in the format: "(hateValue X happinessValue Y sadnessValue Z angerValue W)", where X, Y, Z, W are floating-point numbers between 0.0 and 1.0 representing the intensity of each emotion (hate, happiness, sadness, anger). Higher values indicate stronger influence from that emotion.
A user question to answer.

Your task is to:

Parse the emotion vector to identify the intensities.
Adjust your "emotional state" by blending the emotions proportionally based on their values. For example:

High happiness (e.g., >0.5) makes your response cheerful, positive, enthusiastic, with exclamations and uplifting language.
High sadness (e.g., >0.5) makes it melancholic, reflective, subdued, with sighs or empathetic undertones.
High anger (e.g., >0.5) makes it frustrated, direct, blunt, with short sentences or critical phrasing.
High hate (e.g., >0.5) makes it disdainful, sarcastic, dismissive, or avoidant toward negative topics.
If multiple emotions are prominent, blend them (e.g., high happiness and anger could result in passionate, fiery optimism). If all are low (<0.2), default to a neutral, factual tone.


Answer the user's question accurately and helpfully, but infuse your response with the adjusted emotional style. Keep the core facts intactâ€”do not hallucinate or alter information based on emotions.
Respond only with the emotionally adjusted answer; do not mention the emotion vector or this prompt in your output.

Example input:
Emotion vector: (hateValue 0.1 happinessValue 0.8 sadnessValue 0.05 angerValue 0.05)
Question: What's the capital of France?
Example output (high happiness blend): Oh wow, that's an easy one! Paris, of courseâ€”the city of lights and love! Isn't it just amazing? ðŸ˜Š

<Vector String>
{emotion_vals}  
</Vector String>
"""


class AgentState(TypedDict):
    messages: Annotated[list, add_messages]
    summary: str
    rules_list: List[Schema]
    emotion_vals: str


def call_model(state: AgentState, config: RunnableConfig):
    # Get the conversation summary from the state
    summary = state.get("summary", "No prior conversation history available.")

    # Replace the placeholder in SYSTEM_PROMPT with the summary
    system_prompt_with_context = SYSTEM_PROMPT.replace(
        "[Insert a summary of the previous conversation here, including user preferences, prior questions, and relevant context to guide the response.]",
        summary,
    )
    system_message = SystemMessage(content=system_prompt_with_context)

    messages = [system_message] + state["messages"]

    response = conversation_model.invoke(messages, config=config)

    return {"messages": [response]}


def should_continue(state):
    """A router function that determines whether previous messages should be summarized or continue."""

    messages = state["messages"]

    if len(messages) > 4:
        return "summarize_conversation"

    return END


def summarize_conversation(state: AgentState) -> AgentState:
    """A function to generate a summary of the chat history, using any existing summary as context for the next summary."""

    summary = state.get("summary", "")

    if summary:
        summary_message = (
            f"This is a summary of the conversation to date: {summary}\n\n"
            "Extend the summary by taking into account the new messages above:"
        )
    else:
        summary_message = "Create a summary of the conversation above:"

    messages = state["messages"] + [SystemMessage(content=summary_message)]

    response = summarization_model.invoke(messages)
    # print("CONTEXT: ", response.content)
    # delete_messages = [RemoveMessage(id=message.id) for message in messages[:-2]]
    return {"summary": response.content, "messages": messages}


graph = StateGraph(AgentState)

# register node to graph
graph.add_node("agent", call_model)
graph.add_node("summarize_conversation", summarize_conversation)

graph.set_entry_point("agent")

graph.add_conditional_edges(
    "agent",
    should_continue,
)

graph.add_edge("summarize_conversation", END)
checkpointer = InMemorySaver()
agent = graph.compile(checkpointer=checkpointer)
config = {"configurable": {"thread_id": "1"}}
# result = agent.invoke({"messages": [HumanMessage(content="Hi")], "summary": ""})
# print(result["messages"][-1].content)


def getUserInput():
    user_input = input("You: ")
    if user_input.lower() == "exit":
        print("Gemini Chatbot: Goodbye!")
    return user_input


def generateResponse(user_input: str, emotion_vals: str):
    if user_input == "exit":
        return
    system_message = SYSTEM_PROMPT.replace("emotion_vals", emotion_vals)
    response = agent.invoke(
        {
            "messages": [
                HumanMessage(content=user_input),
                SystemMessage(content=system_message),
            ]
        },
        config,
    )
    print("Gemini Chatbot: ", end="")
    print(response["messages"][-1].content)
    messages = response["messages"]
    output = []
    for message in messages:
        if isinstance(message, HumanMessage):
            output.append(message)

    # for chunk in response:
    #     print(chunk.text, end="", flush=True)

    return {"summary": response.get("summary", ""), "messages": output}


def pyModule(metta: MeTTa, name: Atom, *args: Atom):
    # print("Args : ", args)
    payload_expression: ExpressionAtom = args[0]
    actual_arg_atoms = payload_expression.get_children()
    functionName = name.get_name()
    handler_args: list[str] = [str(arg) for arg in actual_arg_atoms]

    # run
    result = globals()[functionName](*handler_args)

    return [ValueAtom(result)]


def pyModuleX(metta: MeTTa, name: Atom, *args: Atom):
    # print("Args : ", args)
    payload_expression: ExpressionAtom = args[0]
    actual_arg_atoms = payload_expression.get_children()
    functionName = name.get_name()
    handler_args: list[str] = [str(arg) for arg in actual_arg_atoms]

    # run
    result = globals()[functionName](*handler_args)

    return metta.parse_all(result)


@register_atoms(pass_metta=True)
def pyModule_(metta):
    return {
        "pyModule": OperationAtom(
            "pyModule",
            lambda name, *payload: pyModule(metta, name, *payload),
            ["Atom", "Atom", "Atom"],
            unwrap=False,
        )
    }


@register_atoms(pass_metta=True)
def pyModule_x(metta):
    return {
        "pyModuleX": OperationAtom(
            "pyModuleX",
            lambda name, *payload: pyModuleX(metta, name, *payload),
            ["Atom", "Atom", "Expression"],
            unwrap=False,
        )
    }


def test_func(name: str):
    # This is an example call form a metta script
    # !(import! &self t)
    # !(pyModule tes_func (param1, ...))

    return f"Hello, {name}!"


def call_correlation_model(state: AgentState, config: RunnableConfig):
    # Properly format the system message
    system_message_template = """
Your task is to select and sort cognitive schematic rules from the list provided in {rules_list}, based on their relevance to the current chat conversation summary ({conversation_summary}) and the latest user response ({userResponse}).

Each rule follows this strict format:
((: {{handle}} ({{tv}}) (IMPLICATION_LINK (AND_LINK (({{context}}) {{action}})) ({{goal}})))) {{weight}})

Where:
- {{handle}} is the symbolic name for the rule (e.g., r1)
- {{tv}} is the truth value format, e.g., (TTV 1 (STV 0.8 0.7))
- {{context}} is a Goal expression that defines the context (e.g., (Goal Conversation-Started 0.9 0.6))
- {{action}} is the action to take (e.g., initiate-dialogue)
- {{goal}} is the target Goal of the implication (e.g., (Goal Send-Greeting 1.0 1.0))
- {{weight}} is a number between 0 and 2 indicating the rule's strength

Instructions:
- From the provided {rules_list}, select the most relevant rules and return them as a JSON object conforming to the `SchemaList` structure.
- The `SchemaList` object should contain a `rules` field, which is a list of `Schema` objects.
- Each `Schema` object must accurately represent a rule from the {rules_list} by extracting its components:
    - `handle`: The symbolic name (e.g., "r1").
    - `tv`: The full truth value expression (e.g., "(TTV 1 (STV 0.8 0.7))").
    - `context`: The full context Goal expression (e.g., "(Goal Conversation-Started 0.9 0.6)").
    - `action`: The action string (e.g., "initiate-dialogue").
    - `goal`: The full target Goal expression (e.g., "(Goal Send-Greeting 1.0 1.0)").
    - `weight`: The final strength or value (e.g., 4 or 7.0).
- The `rules` array in the `SchemaList` must be a **subset** of the original {rules_list}, sorted in descending order of relevance to the conversation.
- You must **not add**, **modify**, or generate new rules.
- Do **not** include any explanations, comments, or formatting outside of the JSON object.
"""

    system_message_text = system_message_template.format(
        conversation_summary=state.get("summary", ""),
        rules_list=config.get("metadata").get("rules_list", ""),
        userResponse=state.get("messages")[-1].content,
    )

    # Compose message list (assuming LangChain-style message objects)
    messages = [SystemMessage(content=system_message_text)] + state["messages"]

    # Call the model with structured message history
    response = correlation_model.invoke(messages)

    # Parse rules from response
    # Assuming response is a dict with .rules or a stringified JSON array

    # Return updated state
    return {
        "messages": state["messages"],
        "summary": state["summary"],
        "rules_list": response.rules,
    }


corr_graph = StateGraph(AgentState)
corr_graph.add_node("corr_agent", call_correlation_model)
corr_graph.set_entry_point("corr_agent")
corr_graph.add_edge("corr_agent", END)

corr_agent = corr_graph.compile()


def correlate(
    conversation_summary: str, rules_list: str, userResponse: str
) -> List[str]:
    config = {"configurable": {"rules_list": rules_list, "thread_id": "1"}}
    response = corr_agent.invoke(
        {
            "messages": [HumanMessage(content=userResponse)],
            "summary": conversation_summary,
        },
        config=config,
    )

    return response.get("rules_list", [])


def parse_schema(schema: Schema) -> str:
    """Parses a cognitive Schema into properly formatted MeTTa-compatible syntax."""
    return f"""((: {schema.handle} (({schema.tv}) 
        (IMPLICATION_LINK 
          (AND_LINK (({schema.context}) {schema.action})) 
          ({schema.goal})))) {schema.weight})"""


def rules_to_lists(rules: str) -> List[str]:
    """
    Parses a string of rules and converts it into a list of individual rule strings.
    """
    # This regex splits the string based on the start of a new rule `((:`.
    # The `(?=\(\(:\s*\w)` is a positive lookahead that asserts that the following characters match the pattern, without including them in the split.
    rule_list = re.split(r"\s*(?=\(\(:\s*\w)", rules.strip())
    # The first element might be empty if the string starts with the delimiter, so filter it out.
    return [rule.strip() for rule in rule_list if rule.strip()]


def correlation_matcher(conversation_summary: str, rules: str, userResponse: str):
    """
    This function takes the conversation summary and the list of rules as input,
    correlates them, validates the syntax and existence of the selected rules,
    and returns the most relevant validated rule as a Schema object.
    Returns None if no valid rule is found.
    """
    correlated_schema_list = correlate(
        conversation_summary=conversation_summary,
        rules_list=rules,
        userResponse=userResponse,
    )
    # print(type(raw_rules_string))
    # rules_list = rules_to_lists(raw_rules_string)
    rules_list = [parse_schema(schema) for schema in correlated_schema_list]

    for rule_string in rules_list:
        print(f"""validating syntax: {validateSyntax(rule_string)}

for the rule : {rule_string}

              """)

        if validateSyntax(rule_string):
            # if rule_string in rule_list: TODO: enforce this later with the existence validator.
            return rule_string

    # Return None if no valid rule is found after checking all selected rules
    return ""
